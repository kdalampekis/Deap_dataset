{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfknbVhHhJqx"
      },
      "source": [
        "##Install necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iiKnpFelIFy",
        "outputId": "9f59b661-5bd9-4db1-c8f7-fd1c83bb1ada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (1.13.1)\n",
            "Requirement already satisfied: pandas in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
            "Requirement already satisfied: matplotlib in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (3.9.3)\n",
            "Requirement already satisfied: seaborn in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.4.5)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install numpy scipy pandas matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZIIeHAlhksp",
        "outputId": "2b640d25-fa12-4e51-f8ba-a2f44364f85c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (2.5.1)\n",
            "Requirement already satisfied: torchvision in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (0.20.1)\n",
            "Requirement already satisfied: torchaudio in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (2.5.1)\n",
            "Requirement already satisfied: filelock in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install torch torchvision torchaudio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK531gaqfgfF",
        "outputId": "28b0f80b-7768-4d3a-8c0e-314bce39fdc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
            "Requirement already satisfied: scipy in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (3.9.3)\n",
            "Requirement already satisfied: scikit-learn in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (1.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install numpy pandas scipy matplotlib scikit-learn \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting torch-scatter\n",
            "  Using cached torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Using cached torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "Requirement already satisfied: scipy in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch-sparse) (1.13.1)\n",
            "Collecting aiohttp (from torch-geometric)\n",
            "  Using cached aiohttp-3.11.11-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: fsspec in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: pyparsing in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from torch-geometric) (4.67.1)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch-geometric)\n",
            "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->torch-geometric)\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp->torch-geometric)\n",
            "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric)\n",
            "  Using cached frozenlist-1.5.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (13 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->torch-geometric)\n",
            "  Using cached multidict-6.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->torch-geometric)\n",
            "  Using cached propcache-0.2.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch-geometric)\n",
            "  Using cached yarl-1.18.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (69 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "Using cached aiohttp-3.11.11-cp39-cp39-macosx_11_0_arm64.whl (455 kB)\n",
            "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
            "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Using cached frozenlist-1.5.0-cp39-cp39-macosx_11_0_arm64.whl (52 kB)\n",
            "Using cached multidict-6.1.0-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
            "Using cached propcache-0.2.1-cp39-cp39-macosx_11_0_arm64.whl (45 kB)\n",
            "Using cached yarl-1.18.3-cp39-cp39-macosx_11_0_arm64.whl (92 kB)\n",
            "Building wheels for collected packages: torch-scatter, torch-sparse\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[57 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m running bdist_wheel\n",
            "  \u001b[31m   \u001b[0m running build\n",
            "  \u001b[31m   \u001b[0m running build_py\n",
            "  \u001b[31m   \u001b[0m creating build\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-3.9\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-3.9/torch_scatter\n",
            "  \u001b[31m   \u001b[0m copying torch_scatter/placeholder.py -> build/lib.macosx-10.9-universal2-3.9/torch_scatter\n",
            "  \u001b[31m   \u001b[0m copying torch_scatter/__init__.py -> build/lib.macosx-10.9-universal2-3.9/torch_scatter\n",
            "  \u001b[31m   \u001b[0m copying torch_scatter/segment_csr.py -> build/lib.macosx-10.9-universal2-3.9/torch_scatter\n",
            "  \u001b[31m   \u001b[0m copying torch_scatter/segment_coo.py -> build/lib.macosx-10.9-universal2-3.9/torch_scatter\n",
            "  \u001b[31m   \u001b[0m copying torch_scatter/utils.py -> build/lib.macosx-10.9-universal2-3.9/torch_scatter\n",
            "  \u001b[31m   \u001b[0m copying torch_scatter/scatter.py -> build/lib.macosx-10.9-universal2-3.9/torch_scatter\n",
            "  \u001b[31m   \u001b[0m copying torch_scatter/testing.py -> build/lib.macosx-10.9-universal2-3.9/torch_scatter\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-3.9/torch_scatter/composite\n",
            "  \u001b[31m   \u001b[0m copying torch_scatter/composite/std.py -> build/lib.macosx-10.9-universal2-3.9/torch_scatter/composite\n",
            "  \u001b[31m   \u001b[0m copying torch_scatter/composite/__init__.py -> build/lib.macosx-10.9-universal2-3.9/torch_scatter/composite\n",
            "  \u001b[31m   \u001b[0m copying torch_scatter/composite/logsumexp.py -> build/lib.macosx-10.9-universal2-3.9/torch_scatter/composite\n",
            "  \u001b[31m   \u001b[0m copying torch_scatter/composite/softmax.py -> build/lib.macosx-10.9-universal2-3.9/torch_scatter/composite\n",
            "  \u001b[31m   \u001b[0m running egg_info\n",
            "  \u001b[31m   \u001b[0m writing torch_scatter.egg-info/PKG-INFO\n",
            "  \u001b[31m   \u001b[0m writing dependency_links to torch_scatter.egg-info/dependency_links.txt\n",
            "  \u001b[31m   \u001b[0m writing requirements to torch_scatter.egg-info/requires.txt\n",
            "  \u001b[31m   \u001b[0m writing top-level names to torch_scatter.egg-info/top_level.txt\n",
            "  \u001b[31m   \u001b[0m reading manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
            "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
            "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
            "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
            "  \u001b[31m   \u001b[0m writing manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
            "  \u001b[31m   \u001b[0m running build_ext\n",
            "  \u001b[31m   \u001b[0m building 'torch_scatter._scatter_cpu' extension\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-universal2-3.9\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-universal2-3.9/csrc\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-universal2-3.9/csrc/cpu\n",
            "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -iwithsysroot/System/Library/Frameworks/System.framework/PrivateHeaders -iwithsysroot/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/Headers -Werror=implicit-function-declaration -Wno-error=unreachable-code -DWITH_PYTHON -Icsrc -I/Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include -I/Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/api/include -I/Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/TH -I/Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/THC -I/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/include/python3.9 -c csrc/cpu/scatter_cpu.cpp -o build/temp.macosx-10.9-universal2-3.9/csrc/cpu/scatter_cpu.o -O3 -Wno-sign-compare -arch arm64 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_clang\" -DPYBIND11_STDLIB=\"_libcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1002\" -DTORCH_EXTENSION_NAME=_scatter_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
            "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/autograd/variable.h:6:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/ATen/Tensor.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/ATen/core/Tensor.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/ATen/core/TensorBody.h:11:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/c10/core/Device.h:3:\n",
            "  \u001b[31m   \u001b[0m /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/c10/core/DeviceType.h:10:10: fatal error: 'cstddef' file not found\n",
            "  \u001b[31m   \u001b[0m    10 | #include <cstddef>\n",
            "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~\n",
            "  \u001b[31m   \u001b[0m 1 error generated.\n",
            "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[31m  ERROR: Failed building wheel for torch-scatter\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for torch-scatter\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[90 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
            "  \u001b[31m   \u001b[0m running bdist_wheel\n",
            "  \u001b[31m   \u001b[0m /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/utils/cpp_extension.py:497: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  \u001b[31m   \u001b[0m   warnings.warn(msg.format('we could not find ninja.'))\n",
            "  \u001b[31m   \u001b[0m running build\n",
            "  \u001b[31m   \u001b[0m running build_py\n",
            "  \u001b[31m   \u001b[0m creating build\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-3.9\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/matmul.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/permute.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/add.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/reduce.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/narrow.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/masked_select.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/cat.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/eye.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/convert.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/coalesce.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/__init__.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/tensor.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/bandwidth.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/mul.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/transpose.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/utils.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/diag.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/rw.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/storage.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/sample.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/spspmm.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/index_select.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/saint.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/select.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/typing.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/spadd.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/testing.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/spmm.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m copying torch_sparse/metis.py -> build/lib.macosx-10.9-universal2-3.9/torch_sparse\n",
            "  \u001b[31m   \u001b[0m running egg_info\n",
            "  \u001b[31m   \u001b[0m writing torch_sparse.egg-info/PKG-INFO\n",
            "  \u001b[31m   \u001b[0m writing dependency_links to torch_sparse.egg-info/dependency_links.txt\n",
            "  \u001b[31m   \u001b[0m writing requirements to torch_sparse.egg-info/requires.txt\n",
            "  \u001b[31m   \u001b[0m writing top-level names to torch_sparse.egg-info/top_level.txt\n",
            "  \u001b[31m   \u001b[0m reading manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
            "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
            "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/css'\n",
            "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/html'\n",
            "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/tests'\n",
            "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/examples'\n",
            "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/benchmark'\n",
            "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
            "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'benchmark'\n",
            "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
            "  \u001b[31m   \u001b[0m writing manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
            "  \u001b[31m   \u001b[0m running build_ext\n",
            "  \u001b[31m   \u001b[0m building 'torch_sparse._relabel_cpu' extension\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-universal2-3.9\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-universal2-3.9/csrc\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-universal2-3.9/csrc/cpu\n",
            "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -iwithsysroot/System/Library/Frameworks/System.framework/PrivateHeaders -iwithsysroot/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/Headers -Werror=implicit-function-declaration -Wno-error=unreachable-code -DWITH_PYTHON -Icsrc -I/private/var/folders/0q/44gwyztj0dlbkt4vjvhbq7v80000gn/T/pip-install-0phgh10t/torch-sparse_42739761e1b04c7d903243c56c4b9ea5/third_party/parallel-hashmap -I/Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include -I/Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/api/include -I/Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/TH -I/Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/THC -I/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/include/python3.9 -c csrc/cpu/relabel_cpu.cpp -o build/temp.macosx-10.9-universal2-3.9/csrc/cpu/relabel_cpu.o -O3 -Wno-sign-compare -D_LIBCPP_DISABLE_AVAILABILITY -arch arm64 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_clang\" -DPYBIND11_STDLIB=\"_libcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1002\" -DTORCH_EXTENSION_NAME=_relabel_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  \u001b[31m   \u001b[0m In file included from csrc/cpu/relabel_cpu.cpp:1:\n",
            "  \u001b[31m   \u001b[0m In file included from csrc/cpu/relabel_cpu.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/autograd/autograd.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/autograd/variable.h:6:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/ATen/Tensor.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/ATen/core/Tensor.h:3:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/ATen/core/TensorBody.h:11:\n",
            "  \u001b[31m   \u001b[0m In file included from /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/c10/core/Device.h:3:\n",
            "  \u001b[31m   \u001b[0m /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages/torch/include/c10/core/DeviceType.h:10:10: fatal error: 'cstddef' file not found\n",
            "  \u001b[31m   \u001b[0m    10 | #include <cstddef>\n",
            "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~\n",
            "  \u001b[31m   \u001b[0m 1 error generated.\n",
            "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[31m  ERROR: Failed building wheel for torch-sparse\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for torch-sparse\n",
            "Failed to build torch-scatter torch-sparse\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (torch-scatter, torch-sparse)\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install torch-scatter torch-sparse torch-geometric\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtRRJn_1lU_o"
      },
      "source": [
        "##Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0dvjjGpypfH",
        "outputId": "8b2c9315-0de0-4d4b-972a-6a27dd3e0318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined data shape: (1280, 40, 8064)\n",
            "Combined labels shape: (1280, 4)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Corrected path for macOS\n",
        "dataset_path = \"/Users/kostasbekis/Emotion_detection/Deap_dataset/deap/data_preprocessed_python\"\n",
        "\n",
        "# List all .dat files in the directory\n",
        "all_files = [os.path.join(dataset_path, file) for file in os.listdir(dataset_path) if file.endswith(\".dat\")]\n",
        "\n",
        "# Initialize lists for storing data and labels\n",
        "all_data = []\n",
        "all_labels = []\n",
        "\n",
        "# Read data and labels from each .dat file\n",
        "for file in all_files:\n",
        "    with open(file, 'rb') as f:\n",
        "        file_data = pickle.load(f, encoding='latin1')  # Use 'latin1' for compatibility\n",
        "        all_data.append(file_data['data'])\n",
        "        all_labels.append(file_data['labels'])\n",
        "\n",
        "# Convert lists to numpy arrays for easier processing\n",
        "all_data = np.concatenate(all_data, axis=0)\n",
        "all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "print(\"Combined data shape:\", all_data.shape)\n",
        "print(\"Combined labels shape:\", all_labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "c8HEZ8CgzMn2"
      },
      "outputs": [],
      "source": [
        "np.save('/Users/kostasbekis/Emotion_detection/Deap_dataset/deap/data_preprocessed_python', all_data)\n",
        "np.save('/Users/kostasbekis/Emotion_detection/Deap_dataset/deap/data_preprocessed_python', all_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: scikit-learn in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/kostasbekis/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data normalized. Shape: (1280, 40, 8064)\n",
            "Adjacency matrix shape: (40, 40)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import networkx as nx\n",
        "\n",
        "# Normalize the EEG data across trials\n",
        "def normalize_data(data):\n",
        "    scaler = StandardScaler()\n",
        "    for i in range(data.shape[0]):\n",
        "        data[i, :, :] = scaler.fit_transform(data[i, :, :].T).T\n",
        "    return data\n",
        "\n",
        "# Normalize EEG data\n",
        "normalized_data = normalize_data(all_data)\n",
        "print(\"Data normalized. Shape:\", normalized_data.shape)\n",
        "\n",
        "# Create adjacency matrix for the GNN\n",
        "# For simplicity, we'll use a fully connected graph with equal weights\n",
        "n_channels = normalized_data.shape[1]  # Number of EEG channels (40)\n",
        "adjacency_matrix = np.ones((n_channels, n_channels))  # Fully connected graph\n",
        "np.fill_diagonal(adjacency_matrix, 1)  # Diagonal elements are self-connections\n",
        "\n",
        "print(\"Adjacency matrix shape:\", adjacency_matrix.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features shape: (1280, 40)\n",
            "Labels shape after one-hot encoding: (1280, 4, 2)\n",
            "Train Shape: (896, 40), Validation Shape: (192, 40), Test Shape: (192, 40)\n",
            "Train Labels Shape: (896, 4, 2)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Reshape the data for GNN (nodes x features)\n",
        "# We'll take the average across time steps to reduce dimensionality for simplicity\n",
        "features = np.mean(normalized_data, axis=2)  # Shape: (1280, 40)\n",
        "print(\"Features shape:\", features.shape)\n",
        "\n",
        "# Convert labels to one-hot encoding for multi-class classification\n",
        "labels_categorical = to_categorical(all_labels > 5)  # Threshold 5 for binary classes\n",
        "print(\"Labels shape after one-hot encoding:\", labels_categorical.shape)\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(features, labels_categorical, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Train Shape: {X_train.shape}, Validation Shape: {X_val.shape}, Test Shape: {X_test.shape}\")\n",
        "print(f\"Train Labels Shape: {y_train.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct Broadcasted Adjacency Matrix Shape: (896, 40, 40)\n"
          ]
        }
      ],
      "source": [
        "# Ensure adjacency matrix has correct dimensions for batching\n",
        "batch_size = X_train.shape[0]  # Number of training samples\n",
        "adjacency_matrix_broadcasted = np.repeat(adjacency_matrix[np.newaxis, :, :], batch_size, axis=0)\n",
        "print(\"Correct Broadcasted Adjacency Matrix Shape:\", adjacency_matrix_broadcasted.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated Inputs shape: (896, 40, 1)\n"
          ]
        }
      ],
      "source": [
        "# Add a feature dimension to the node features\n",
        "X_train = np.expand_dims(X_train, axis=-1)  # New shape: (896, 40, 1)\n",
        "X_val = np.expand_dims(X_val, axis=-1)      # New shape: (192, 40, 1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)    # New shape: (192, 40, 1)\n",
        "\n",
        "print(\"Updated Inputs shape:\", X_train.shape)  # Should now be (896, 40, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "X_val_tensor = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
        "X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "adjacency_matrix_tensor = tf.convert_to_tensor(adjacency_matrix[:X_train.shape[0]], dtype=tf.float32)  # Training adjacency matrix\n",
        "adjacency_matrix_val_tensor = tf.convert_to_tensor(adjacency_matrix[:X_val.shape[0]], dtype=tf.float32)  # Validation adjacency matrix\n",
        "adjacency_matrix_test_tensor = tf.convert_to_tensor(adjacency_matrix[:X_test.shape[0]], dtype=tf.float32)  # Test adjacency matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the batch size explicitly\n",
        "batch_size = X_train.shape[0]  # Number of training samples\n",
        "n_nodes = features.shape[1]   # Number of nodes (40 in this case)\n",
        "n_features = 1                # Number of features per node (can adjust if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs shape: (896, 40, 1), Adjacency matrix shape: (896, 40, 40)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Inputs shape: {X_train.shape}, Adjacency matrix shape: {adjacency_matrix_broadcasted.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_tensor shape: (896, 40, 1)\n",
            "adjacency_matrix_tensor shape: (40, 40)\n",
            "y_train shape: (896, 4, 2)\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train_tensor shape:\", X_train_tensor.shape)\n",
        "print(\"adjacency_matrix_tensor shape:\", adjacency_matrix_tensor.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated adjacency_matrix_tensor shape: (896, 40, 40)\n"
          ]
        }
      ],
      "source": [
        "# Expand the adjacency matrix to match the batch size\n",
        "adjacency_matrix_broadcasted = np.expand_dims(adjacency_matrix, axis=0)  # Shape: (1, 40, 40)\n",
        "adjacency_matrix_tensor = np.repeat(adjacency_matrix_broadcasted, X_train_tensor.shape[0], axis=0)  # Shape: (896, 40, 40)\n",
        "\n",
        "# Convert to TensorFlow tensor\n",
        "adjacency_matrix_tensor = tf.convert_to_tensor(adjacency_matrix_tensor, dtype=tf.float32)\n",
        "\n",
        "print(\"Updated adjacency_matrix_tensor shape:\", adjacency_matrix_tensor.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs shape: (896, 40, 1)\n",
            "Adjacency matrix shape: (896, 40, 40)\n",
            "Labels shape: (896, 4, 2)\n"
          ]
        }
      ],
      "source": [
        "print(\"Inputs shape:\", X_train_tensor.shape)  # Should be (batch_size, 40, 1)\n",
        "print(\"Adjacency matrix shape:\", adjacency_matrix_tensor.shape)  # Should be (batch_size, 40, 40)\n",
        "print(\"Labels shape:\", y_train.shape)  # Should be (batch_size, 4, 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node features contain None: False\n",
            "Adjacency matrix contains None: False\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"Node features contain None:\", np.any(np.isnan(X_train)))\n",
        "print(\"Adjacency matrix contains None:\", np.any(np.isnan(adjacency_matrix_tensor)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjacency matrix is symmetric: True\n",
            "Diagonal elements are 1: True\n"
          ]
        }
      ],
      "source": [
        "print(\"Adjacency matrix is symmetric:\", np.allclose(adjacency_matrix, adjacency_matrix.T))\n",
        "print(\"Diagonal elements are 1:\", np.all(np.diag(adjacency_matrix) == 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = X_train.shape[0]\n",
        "adjacency_matrix_tensor = np.repeat(adjacency_matrix[np.newaxis, :, :], batch_size, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (896, 40, 1)\n",
            "Validation data shape: (192, 40, 1)\n",
            "Test data shape: (192, 40, 1)\n",
            "Adjacency matrix shape: (896, 40, 40)\n"
          ]
        }
      ],
      "source": [
        "print(\"Training data shape:\", X_train.shape)\n",
        "print(\"Validation data shape:\", X_val.shape)\n",
        "print(\"Test data shape:\", X_test.shape)\n",
        "print(\"Adjacency matrix shape:\", adjacency_matrix_tensor.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example node features\n",
        "node_features = np.random.rand(896, 40, 1).astype(np.float32)  # Batch of 896 graphs, 40 nodes, 1 feature per node\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example adjacency matrix\n",
        "adjacency_matrix = np.ones((896, 40, 40), dtype=np.float32)  # Batch of 896 graphs, fully connected\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "node_features = np.reshape(node_features, (batch_size, n_nodes, n_features))\n",
        "adjacency_matrix = np.reshape(adjacency_matrix, (batch_size, n_nodes, n_nodes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "node_features = node_features[:10]\n",
        "adjacency_matrix = adjacency_matrix[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Set the environment variable\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "\n",
        "# Now import TensorFlow\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "Legacy Keras enabled: False\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Legacy Keras enabled:\", tf.keras.__version__.startswith(\"2\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch_geometric'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[56], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCNConv\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define graph data\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_gnn as tfgnn\n",
        "import numpy as np\n",
        "\n",
        "# Dummy data\n",
        "batch_size = 8\n",
        "n_nodes = 40\n",
        "n_features = 1\n",
        "\n",
        "# Node features: Shape (batch_size, n_nodes, n_features)\n",
        "node_features = np.random.rand(batch_size, n_nodes, n_features).astype(np.float32)\n",
        "\n",
        "# Adjacency matrix: Shape (batch_size, n_nodes, n_nodes)\n",
        "adjacency_matrix = np.eye(n_nodes, dtype=np.float32)  # Identity matrix for simplicity\n",
        "adjacency_matrix = np.repeat(adjacency_matrix[np.newaxis, :, :], batch_size, axis=0)\n",
        "\n",
        "# Build a graph schema\n",
        "def build_graph_tensor(node_features, adjacency_matrix):\n",
        "    num_nodes = node_features.shape[1]\n",
        "\n",
        "    # Flatten batch for TensorFlow GNN\n",
        "    batch_size = node_features.shape[0]\n",
        "    node_features_flat = node_features.reshape(-1, n_features)\n",
        "\n",
        "    # Build adjacency list from adjacency matrix\n",
        "    source_nodes, target_nodes = np.where(adjacency_matrix[0] > 0)  # Use the first graph as an example\n",
        "    source_nodes = np.tile(source_nodes, batch_size)  # Repeat for batch\n",
        "    target_nodes = np.tile(target_nodes, batch_size)\n",
        "\n",
        "    # Create TensorFlow GNN GraphTensor\n",
        "    graph = tfgnn.GraphTensor.from_pieces(\n",
        "        node_sets={\n",
        "            \"nodes\": tfgnn.NodeSet.from_fields(\n",
        "                features={\"feature\": tf.convert_to_tensor(node_features_flat)},\n",
        "                sizes=tf.convert_to_tensor([num_nodes] * batch_size)\n",
        "            )\n",
        "        },\n",
        "        edge_sets={\n",
        "            \"edges\": tfgnn.EdgeSet.from_fields(\n",
        "                sizes=tf.convert_to_tensor([len(source_nodes)]),\n",
        "                adjacency=tfgnn.Adjacency.from_indices(\n",
        "                    source=(\"nodes\", tf.convert_to_tensor(source_nodes, dtype=tf.int32)),\n",
        "                    target=(\"nodes\", tf.convert_to_tensor(target_nodes, dtype=tf.int32))\n",
        "                )\n",
        "            )\n",
        "        }\n",
        "    )\n",
        "    return graph\n",
        "\n",
        "# Build graph tensor\n",
        "graph_tensor = build_graph_tensor(node_features, adjacency_matrix)\n",
        "\n",
        "# Define the GNN model using TensorFlow GNN\n",
        "class GCNModel(tf.keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "        self.gnn_layer = tfgnn.keras.layers.GraphUpdate(\n",
        "            node_sets={\"nodes\": tfgnn.keras.layers.SimpleConv(units, activation=\"relu\")}\n",
        "        )\n",
        "        self.dense = tf.keras.layers.Dense(units, activation=\"relu\")\n",
        "\n",
        "    def call(self, graph_tensor):\n",
        "        graph_tensor = self.gnn_layer(graph_tensor)\n",
        "        node_features = graph_tensor.node_sets[\"nodes\"][\"feature\"]\n",
        "        return self.dense(node_features)\n",
        "\n",
        "# Instantiate and compile the model\n",
        "units = 32\n",
        "model = GCNModel(units)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")  # Adjust loss as needed\n",
        "\n",
        "# Forward pass\n",
        "output = model(graph_tensor)\n",
        "print(\"Output shape:\", output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    [X_train, adjacency_matrix_broadcasted[:X_train.shape[0]]],  # Features and adjacency matrix for training\n",
        "    [y_train[:, 0, :], y_train[:, 1, :], y_train[:, 2, :], y_train[:, 3, :]],  # Separate outputs\n",
        "    validation_data=(\n",
        "        [X_val, adjacency_matrix_broadcasted[:X_val.shape[0]]],  # Validation data\n",
        "        [y_val[:, 0, :], y_val[:, 1, :], y_val[:, 2, :], y_val[:, 3, :]]  # Validation labels\n",
        "    ),\n",
        "    epochs=20,\n",
        "    batch_size=32\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "loss, valence_acc, arousal_acc, dominance_acc, liking_acc = model.evaluate(\n",
        "    [X_test, adjacency_matrix_broadcasted[:X_test.shape[0]]],\n",
        "    [y_test[:, 0, :], y_test[:, 1, :], y_test[:, 2, :], y_test[:, 3, :]]\n",
        ")\n",
        "\n",
        "print(f\"Valence Accuracy: {valence_acc:.2f}\")\n",
        "print(f\"Arousal Accuracy: {arousal_acc:.2f}\")\n",
        "print(f\"Dominance Accuracy: {dominance_acc:.2f}\")\n",
        "print(f\"Liking Accuracy: {liking_acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict([X_test, adjacency_matrix_broadcasted[:X_test.shape[0]]])\n",
        "\n",
        "# Process predictions and ground truth\n",
        "y_pred_classes = [np.argmax(output, axis=-1) for output in y_pred]\n",
        "y_test_classes = [np.argmax(output, axis=-1) for output in [y_test[:, 0, :], y_test[:, 1, :], y_test[:, 2, :], y_test[:, 3, :]]]\n",
        "\n",
        "# Confusion matrix for each output\n",
        "for i, label_name in enumerate([\"Valence\", \"Arousal\", \"Dominance\", \"Liking\"]):\n",
        "    cm = confusion_matrix(y_test_classes[i], y_pred_classes[i])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"Confusion Matrix: {label_name}\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Classification Report for {label_name}:\")\n",
        "    print(classification_report(y_test_classes[i], y_pred_classes[i]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspektral\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39m__version__)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import spektral\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Spektral version:\", spektral.__version__)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
